---
title:       "逻辑回归"
subtitle:    ""
description: "逻辑回归"
date:        "2025-01-24T04:26:43+08:00"
author:      "杨子逸"
image:       ""
tags:        ["程序", "算法", "机器学习"]
categories:  ["Tech"]
draft:       false
---

# 逻辑回归
逻辑回归（Logistic Regression）是一种广义线性模型，常用于二分类问题。它通过使用逻辑函数（Sigmoid函数）将线性回归的输出映射到一个概率值，从而实现分类。

## 逻辑回归公式

逻辑回归的核心是逻辑函数（Sigmoid函数），其公式为：

$$ \[ \sigma(z) = \frac{1}{1 + e^{-z}} \] $$

其中，\( z \) 是线性回归的结果，即：

$$ \[ z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n \] $$

逻辑回归模型的输出是一个介于0和1之间的概率值，表示样本属于某一类别的概率。具体的预测类别可以通过设定一个阈值（通常为0.5）来确定。

## 逻辑回归的损失函数

为了训练逻辑回归模型，我们需要定义一个损失函数。逻辑回归常用的损失函数是对数损失函数（Log Loss），其公式为：

$$ \[ L(y, \hat{y}) = - \left( y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \right) \] $$

其中，$$ \( y \)  $$是真实标签，$$ \( \hat{y} \)  $$是模型预测的概率值。

## 梯度下降法

为了最小化损失函数，我们可以使用梯度下降法。梯度下降法通过迭代更新模型参数，使损失函数逐渐减小。参数更新公式为：

$$ \[ \beta_j := \beta_j - \alpha \frac{\partial L}{\partial \beta_j} \] $$

其中，\( \alpha \) 是学习率，\( \frac{\partial L}{\partial \beta_j} \) 是损失函数对参数 \( \beta_j \) 的偏导数。

通过不断迭代上述过程，最终我们可以得到一个最优的逻辑回归模型。


## 例子

假设我们有一个数据集，包含学生的学习时间（小时）和他们是否通过考试的结果（通过=1，未通过=0）。我们可以使用逻辑回归来预测一个学生是否会通过考试。

### 数据集

| 学习时间（小时） | 是否通过考试 |
|----------------|------------|
| 1              | 0          |
| 2              | 0          |
| 3              | 0          |
| 4              | 1          |
| 5              | 1          |
| 6              | 1          |

### 模型训练

我们使用学习时间作为特征$$ \( x \) $$，通过训练逻辑回归模型得到参数 $$ \( \beta_0 \) 和 \( \beta_1 \) $$ 。

### 模型预测

假设训练得到的模型参数为 $$ \( \beta_0 = -4 \) $$ 和 $$ \( \beta_1 = 1 \) $$ ，则逻辑回归模型为：

$$ \[ z = -4 + 1 \cdot x \] $$

通过逻辑函数计算概率：

$$ \[ \sigma(z) = \frac{1}{1 + e^{-(-4 + 1 \cdot x)}} \] $$

当学习时间为4小时时，计算得到：

$$ \[ z = -4 + 1 \cdot 4 = 0 \] $$
$$ \[ \sigma(0) = \frac{1}{1 + e^0} = 0.5 \] $$

因此，学习4小时通过考试的概率为0.5。根据阈值0.5，我们预测该学生会通过考试。

通过这种方式，逻辑回归可以帮助我们根据输入特征预测分类结果。